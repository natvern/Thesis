{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80bc9016-977d-44e2-83a6-b37316d58171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "import gym_platoon\n",
    "import sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21342e3-4a7a-4d6d-a5a7-f98e7c1d1848",
   "metadata": {},
   "source": [
    "# From DQN tutorial on Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce75a482-511a-4e1a-a08f-cf51670b22e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration paramaters for the whole setup\n",
    "seed = 42\n",
    "gamma = 0.8  # Discount factor for past rewards\n",
    "epsilon = 1.0  # Epsilon greedy parameter\n",
    "epsilon_min = 0.1  # Minimum epsilon greedy parameter\n",
    "epsilon_max = 1.0  # Maximum epsilon greedy parameter\n",
    "epsilon_interval = (\n",
    "    epsilon_max - epsilon_min\n",
    ")  # Rate at which to reduce chance of random action being taken\n",
    "batch_size = 32  # Size of batch taken from replay buffer\n",
    "max_steps_per_episode = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "353d9da4-cfef-46e5-a6ca-644c3b3d1709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 10  0  0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/srahmoun/opt/anaconda3/envs/rlsc/lib/python3.7/site-packages/gym/spaces/box.py:74: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  \"Box bound precision lowered by casting to {}\".format(self.dtype)\n"
     ]
    }
   ],
   "source": [
    "# Platooning Environment defined in gym-platoon\n",
    "env = gym.make('platoon-v1')\n",
    "env.seed(seed)\n",
    "num_states = env.observation_space.shape[0]\n",
    "print(env.reset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eac902ed-efce-416d-9371-a03cbcbcb81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-01 06:57:17.991757: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-01 06:57:17.993494: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 8. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "num_actions = 9\n",
    "\n",
    "\n",
    "def create_q_model():\n",
    "    \n",
    "    inputs = layers.Input(shape=(num_states,))\n",
    "    layer1 = layers.Dense(256, activation=\"relu\")(inputs)\n",
    "    layer2 = layers.Dense(256, activation=\"relu\")(layer1)\n",
    "    action = layers.Dense(1, activation=\"linear\")(layer2)\n",
    "\n",
    "\n",
    "    return keras.Model(inputs=inputs, outputs=action)\n",
    "\n",
    "\n",
    "# The first model makes the predictions for Q-values which are used to\n",
    "# make a action.\n",
    "model = create_q_model()\n",
    "# Build a target model for the prediction of future rewards.\n",
    "# The weights of a target model get updated every 10000 steps thus when the\n",
    "# loss between the Q-values is calculated the target Q-value is stable.\n",
    "model_target = create_q_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6102426-fe03-4243-8d72-d122043e1754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translateAction(action):\n",
    "    if action == 0:\n",
    "        return [1,1]\n",
    "    if action == 1:\n",
    "        return [1,0]\n",
    "    if action == 2: \n",
    "        return [1,-1]\n",
    "    if action == 3:\n",
    "        return [-1, 1]\n",
    "    if action == 4:\n",
    "        return [-1, 0]\n",
    "    if action == 5:\n",
    "        return [-1,-1]\n",
    "    if action == 6:\n",
    "        return [0,-1]\n",
    "    if action == 7:\n",
    "        return [0,1]\n",
    "    if action == 8:\n",
    "        return [0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4aaae6d-795c-42ed-bf61-2fa7306155a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translateState(state):\n",
    "    xl = [state[0], state[1]] \n",
    "    vl = [state[2], state[3]]\n",
    "    return xl, vl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d7f363ad-a434-4cc9-b6f2-309c4eb11aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running reward: -138.59 at episode 666, frame count 10000\n"
     ]
    }
   ],
   "source": [
    "# Adam Optimizer w/ Learning rate\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.00025, clipnorm=1.0)\n",
    "\n",
    "# Experience replay buffers\n",
    "action_history = []\n",
    "state_history = []\n",
    "state_next_history = []\n",
    "rewards_history = []\n",
    "done_history = []\n",
    "episode_reward_history = []\n",
    "running_reward = 0\n",
    "episode_count = 0\n",
    "frame_count = 0\n",
    "# Number of frames to take random action and observe output\n",
    "epsilon_random_frames = 50000\n",
    "# Number of frames for exploration\n",
    "epsilon_greedy_frames = 1000000.0\n",
    "# Maximum replay length\n",
    "max_memory_length = 100000\n",
    "# Train the model after 4 actions\n",
    "update_after_actions = 4\n",
    "# How often to update the target network\n",
    "update_target_network = 10000\n",
    "# Using huber loss for stability\n",
    "loss_function = keras.losses.Huber()\n",
    "# Plotting purposes\n",
    "episodes = []\n",
    "cumulative_reward = []\n",
    "cumulative_crashes = []\n",
    "running_crashes = 0\n",
    "\n",
    "while (episode_count < 800):  # Run until solved\n",
    "    state = np.array(env.reset())\n",
    "    xl, vl = translateState(state)\n",
    "    cont = sc.Controller(xl, vl)\n",
    "    episode_reward = 0\n",
    "    episode_crash = 0\n",
    "    \n",
    "\n",
    "    for timestep in range(1, max_steps_per_episode):\n",
    "        # env.render(); Adding this line would show the attempts\n",
    "        # of the agent in a pop up window.\n",
    "        frame_count += 1\n",
    "\n",
    "        # Use epsilon-greedy for exploration\n",
    "        if frame_count < epsilon_random_frames or epsilon > np.random.rand(1)[0]:\n",
    "            # Take random action\n",
    "            action = np.random.choice(num_actions)\n",
    "        else:\n",
    "            # Predict action Q-values\n",
    "            # From environment state\n",
    "            state_tensor = tf.convert_to_tensor(state)\n",
    "            state_tensor = tf.expand_dims(state_tensor, 0)\n",
    "            action_probs = model(state_tensor, training=False)\n",
    "            # Take best action\n",
    "            action = tf.argmax(action_probs[0]).numpy()\n",
    "\n",
    "        # Decay probability of taking random action\n",
    "        epsilon -= epsilon_interval / epsilon_greedy_frames\n",
    "        epsilon = max(epsilon, epsilon_min)\n",
    "\n",
    "        # Apply the sampled action in our environment\n",
    "        state_next, reward, done, _ = env.step(action)\n",
    "        state_next = state_next\n",
    "\n",
    "        if (not cont.isSafe(translateAction(action))):\n",
    "            reward = -400 \n",
    "        \n",
    "        episode_reward += reward\n",
    "\n",
    "        # Save actions and states in replay buffer\n",
    "        action_history.append(action)\n",
    "        state_history.append(state)\n",
    "        state_next_history.append(state_next)\n",
    "        done_history.append(done)\n",
    "        rewards_history.append(reward)\n",
    "        state = np.array(state_next)\n",
    "        \n",
    "        if state[0] > state[1]: \n",
    "            episode_crash += 1 \n",
    "\n",
    "        # Update every fourth frame and once batch size is over 32\n",
    "        if frame_count % update_after_actions == 0 and len(done_history) > batch_size:\n",
    "\n",
    "            # Get indices of samples for replay buffers\n",
    "            indices = np.random.choice(range(len(done_history)), size=batch_size)\n",
    "\n",
    "            # Using list comprehension to sample from replay buffer\n",
    "            state_sample = np.array([state_history[i] for i in indices])\n",
    "            state_next_sample = np.array([state_next_history[i] for i in indices])\n",
    "            rewards_sample = [rewards_history[i] for i in indices]\n",
    "            action_sample = [action_history[i] for i in indices]\n",
    "            done_sample = tf.convert_to_tensor(\n",
    "                [float(done_history[i]) for i in indices]\n",
    "            )\n",
    "\n",
    "            # Build the updated Q-values for the sampled future states\n",
    "            # Use the target model for stability\n",
    "            future_rewards = model_target.predict(state_next_sample)\n",
    "            # Q value = reward + discount factor * expected future reward\n",
    "            updated_q_values = rewards_sample + gamma * tf.reduce_max(\n",
    "                future_rewards, axis=1\n",
    "            )\n",
    "\n",
    "            # If final frame set the last value to -1\n",
    "            updated_q_values = updated_q_values * (1 - done_sample) - done_sample\n",
    "\n",
    "            # Create a mask so we only calculate loss on the updated Q-values\n",
    "            masks = tf.one_hot(action_sample, num_actions)\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                # Train the model on the states and updated Q-values\n",
    "                q_values = model(state_sample)\n",
    "\n",
    "                # Apply the masks to the Q-values to get the Q-value for action taken\n",
    "                q_action = tf.reduce_sum(tf.multiply(q_values, masks), axis=1)\n",
    "                # Calculate loss between new Q-value and old Q-value\n",
    "                loss = loss_function(updated_q_values, q_action)\n",
    "\n",
    "            # Backpropagation\n",
    "            grads = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        if frame_count % update_target_network == 0:\n",
    "            # update the the target network with new weights\n",
    "            model_target.set_weights(model.get_weights())\n",
    "            # Log details\n",
    "            template = \"running reward: {:.2f} at episode {}, frame count {}\"\n",
    "            print(template.format(running_reward, episode_count, frame_count))\n",
    "\n",
    "        # Limit the state and reward history\n",
    "        if len(rewards_history) > max_memory_length:\n",
    "            del rewards_history[:1]\n",
    "            del state_history[:1]\n",
    "            del state_next_history[:1]\n",
    "            del action_history[:1]\n",
    "            del done_history[:1]\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    # Update running reward to check condition for solving\n",
    "    episode_reward_history.append(episode_reward)\n",
    "    if len(episode_reward_history) > 100:\n",
    "        del episode_reward_history[:1]\n",
    "    running_reward = np.mean(episode_reward_history)\n",
    "\n",
    "    episode_count += 1\n",
    "    cumulative_reward += [running_reward]\n",
    "    cumulative_crashes += [episode_crash]\n",
    "    episodes += [episode_count]\n",
    "\n",
    "    if running_reward > 40:  # Condition to consider the task solved\n",
    "        print(\"Solved at episode {}!\".format(episode_count))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2bd327d0-3255-4bcf-a74d-81c54853ddad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-169.06\n"
     ]
    }
   ],
   "source": [
    "print(running_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e0a0e070-605d-4d8e-b65e-811eb2428de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "463\n"
     ]
    }
   ],
   "source": [
    "print(running_crashes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aefbf4dd-a339-4e13-b2fb-8d89d2e11cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Cumulative Rewards')\n",
    "plt.plot(episodes, cumulative_crashes, label='DQN for Platooning')\n",
    "plt.xticks(fontsize=6)\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Cumulative rewards')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8cd4972d-31d1-41a6-bd58-955f8e1c1bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 15 102   1   7]\n"
     ]
    }
   ],
   "source": [
    "print(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0332d069-a2ec-4880-90f8-ae47130b0197",
   "metadata": {},
   "source": [
    "*Interesting Note:* Even though it's punished if vehicle 2 gets in front of vehicle 1, the RL still chooses to go in the negative index. 10 - x2 + x1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d3a38f-7c34-43e2-bdcf-a63e5a283ee7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
