\documentclass[a4paper,11pt]{article}

\usepackage{amssymb}
\usepackage{amstext}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{url}

\usepackage{xcolor}
\newcommand{\bluenote}[1]{\color{blue}{ \em #1 }\color{black}}

\usepackage{geometry}
 \geometry{
 a4paper, %letterpaper,
 total={17cm,22.8cm},
 margin=24mm,
 top=22.4mm,
 bottom=25.4mm
 }
 
% Times new roman
\usepackage{mathptmx}

\usepackage[T1]{fontenc}

\thispagestyle{empty} 

\setlength{\parindent}{0pt}


\begin{document}

\date{}

\title{RL Model $\rightarrow$ SC Model}


\maketitle 


\section{State vs. Knowledge Base}
\subsection{Local Knowledge} 
Let's look at the Multi-Agent Reinforcement Learning (MARL) case.
States are joint-states of all the agents. Rewards can be configured to correspond to each joint action.
Assumption is agent A does not know the action of agent B. Environment is non-stationary. \newline
In our state representation, we also consider a joint state+action, meaning that the difference between local 
and joint knowledge base is not highlighted. To my knowledge, this distinction is not considered yet in current MARL work. 

\subsection{Environment Knowledge Base}
\begin{itemize}
    \item \textbf{clock(t)} refers to the current step. 
    \item \textbf{atloc(id,pos)} is state[id]. 
    \item \textbf{speed(id,spd)} is state[id+#agents]. 
    \item \textbf{maxAcc(id,acc)} is fixed to +1/-1. 
    \item \textbf{platoon(idL,...)} is fixed to platoon(0,[1]).
    \item \textbf{mode(id,md)} not considered.
    \item \textbf{safe(id,min,max)} not considered. \textcolor{red}{Goal.} 
\end{itemize}

\subsection{Communication Channels and Protocols}
Since no distinction exists between local and joint, it is assumed that communication is not faulty
and moreover, open at every timestep. 

\section{Attacks}
To consider next. 

\end{document}